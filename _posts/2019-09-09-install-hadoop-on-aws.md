---
layout: post
title:  "AWS에서 하둡(Hadoop) 설치하기 - 1"
date:   2019-09-09
desc: "AWS에서 하둡(Hadoop) 설치하기"
keywords: "hadoop,ssh,aws,분산환경,distributed,hdfs,하둡,아마존,클라우드,aws에 하둡 설치하기,aws hadoop,aws 하둡,hdfs"
categories: [Hadoop]
tags: [hadoop,aws,distributed,HDFS,하둡,아마존]
icon: icon-html
---

개요
===
---

### 본 포스팅은 총 3편으로 다룰 생각이다.
  1. [**하둡이 무엇인지 또 빅데이터 분석에 하둡이 필요한 이유**](https://butsimple.github.io/hadoop/2019/09/09/install-hadoop-on-aws.html)
  2. **AWS EC2 인스턴스를 이용하여 단일노드에 하둡클러스터 구성하기**
  3. **EC2 인스턴스 두 개를 이용하여 멀티노드에 하둡클러스터 구성하기**


<br>
<br>

1.우리는 빅데이터 분석하는데 왜 하둡을 사용하는가?
-----
---
<br>
보통 빅데이터를 표현할 때 5V라는 수식어가 많이 붙는다. 5V중 하나는 Volume 즉 `데이터의 양`이다.  
우리가 이러한 상당한 볼륨의 데이터를 단순히  두개의 폴더로 분류해 저장해야 한다고 생각해보자. CPU가 연산하는 시간보다 데이터 I/O하는 시간이 더 걸릴 수도 있다. 이처럼 `처리하는 작업보다 데이터를 읽어오는 작업이 더 많은 경우 디스크 I/O 병목`이 발생해 시스템 성능이 크게 저하된다.  
아무리 I/O scheduling 및 캐싱을 잘한다하더라도 물리적인 한계에 부딪친다.  

범용 컴퓨터의 경우 HDD의 저장 용량은 1~2 테라 수준이지만 전송속도는 초당 150MB 수준밖에 못 미친다. 전체 데이터를 읽는다고 생각하면 두시간 이상은 족히 걸릴 것이다.  

여기서 해결방법으로 생각 할 수 있는 것은 Disk RAID이다. Disk RAID를 사용한다면 I/O는 줄일 수 있지만 결국엔 `한대의 컴퓨터`이다.  
어느순간 CPU는  처리 임계치를 만날 것이고 컴퓨터를 Scale up하다보면 `비용적인 측면`도 무시 못할 것이다.

그렇다면 비용을 어느정도 부담할 수 있는 기업의 측면에서 보자  
Hadoop이 보편화 되기전까지만해도 많은 기업은 storage와 고성능 컴퓨터들을 하나의 네트워크로 묶어 대규모의 데이터를 처리했다.  
이러한 `그리드 컴퓨팅은 연산 작업이 많은 시스템`에서는 좋은 퍼포먼스를 얻을 수 있지만 `많은 데이터를 접근해야하는 작업을 수행한다면 네트워크 병목현상`이 발생해 노는 클러스터들이 생길 것이다.
<br>
<br>
그렇다면 간단하게 위의 단점들을 보안해보자
> 여러 대의 컴퓨터와 storage를 네트워크로 묶으면 되겠네!!(분산컴퓨팅)

위의 글을 읽으며 이런 생각을 했다면 많이 접근했다.  
그렇다면 우리는 분산컴퓨팅에서 요구하는 `데이터 흐름 메커니즘과 수많은 프로세스 조율(실행 관리 등),하드웨어 장애 관리, 분산된 데이터의 병합 및 정합성 관리` 등 저수준의 구성부터 구현해야한다.

<br>
<br>
이와 같은 일들을 처리해주는 것이 Hadoop 과 HDFS(Hadoop Distributed File System)이다.  
우선 하둡은 `계산이 가능한 여러 노드에 데이터를 분산 저장`한다. 또 하둡은 데이터 지역성(data locality)이라는 특징은 `데이터가 있는 곳에 해당 계산을 수행`시켜 랙간 데이터의 이동(Network I/O)를 최소화 한다.  
하둡을 사용하면 개발자는 데이터의 흐름을 신경쓰지 않고 `데이터 모델 관점에서만 분석`이 가능하다.    
또 하둡은 범용 하드웨어를 사용하여 클러스터를 구성해도 문제 없도록 설계되어 있어 `데이터 복제, 실패 관리, 장애 관리`등을 해주기떄문에 부분 장애가 발생하더라도 사용자는 작업을 계속 이어나갈 수 있다.  

즉 안정적이고 저렴하게 분석시스템을 구축할 수 있다. (심지어 오픈소스이다.)  

이러한 많은 장점들로 많은 기업들은 빅데이터 분석에 Hadoop을 사용하고 있다.

<br>
주석
> 무조건 하둡이 옳다는 말은 아니다. 물리학 같은 고성능의 연산작업이 필요할 때는 그리드 컴퓨팅이 더 나을 수 있다.  
>또 일부 데이터를 조작할 때에는 RDBMS가 더 낫다. 이러한 기술에는 옳고 그름을 따지기보단 자기의 구축하려는 시스템에 따라 알맞게 사용해야할 것이다.


<br>
이제 다음편에서 AWS에 하둡클러스터를 구성해보자.



<br>
<br>
<br>
#####저의 주관적인 생각이 많이 들어가있습니다. 잘못되었다고 생각되시는 부분이 있으시다면 말씀해주세요.
