---
layout: post
title:  "AWS에서 하둡(Hadoop) 설치하기 - 1"
date:   2019-09-09
desc: "AWS에서 하둡(Hadoop) 설치하기"
keywords: "hadoop,ssh,aws,분산환경,distributed,hdfs,하둡,아마존,클라우드"
categories: [Hadoop]
tags: [hadoop,aws,distributed,HDFS,하둡,아마존]
icon: icon-html
---

개요
===
---

### 본 포스팅은 총 3편으로 다룰 생각이다.
  1. **하둡이 무엇인지 또 빅데이터 분석에 하둡이 필요한 이유**
  2. **AWS EC2 인스턴스를 이용하여 단일노드에 하둡클러스터 구성하기**
  3. **EC2 인스턴스 두 개를 이용하여 멀티노드에 하둡클러스터 구성하기**


<br>
<br>

1.우리는 빅데이터 분석하는데 왜 하둡을 사용하는가?
-----
---
<br>
보통 빅데이터를 표현할 때 5V라는 수식어가 많이 붙는다. 5V중 하나는 Volume 즉 `데이터의 양`이다.  
500GB의 데이터가 디스크가 하나달린 컴퓨터에 있다고 생각해보자.
`처리하는 작업보다 데이터를 읽어오는 작업`이 더 많은 경우 디스크 I/O 병목이 발생해 시스템 성능이 크게 저하된다. 아무리 I/O scheduling 및 캐싱을 잘한다하더라도 물리적인 한계에 부딪친다.  
범용 컴퓨터의 경우 HDD의 저장 용량은 1~2 테라 수준이지만 전송속도는 초당 150MB 수준밖에 못 미친다. 전체 데이터를 읽는다고 생각하면 두시간 이상은 족히 걸릴 것이다.  

여기서 해결방법으로 생각 할 수 있는 것은 Disk RAID이다. Disk RAID를 사용한다면 I/O는 줄일 수 있지만 결국엔 `한대의 컴퓨터`이다.  
어느순간 CPU는  처리 임계치를 만날 것이고 컴퓨터를 Scale up하다보면 `비용적인 측면`도 무시 못할 것이다.

그렇다면 비용을 어느정도 부담할 수 있는 기업의 측면에서 보자  
Hadoop이 보편화 되기전까지만해도 많은 기업은 storage와 고성능 컴퓨터들을 하나의 네트워크로 묶어 대규모의 데이터를 처리했다.  
이러한 `그리드 컴퓨팅은 연산 작업이 많은 시스템`에서는 좋은 퍼포먼스를 얻을 수 있지만 `많은 데이터를 접근해야하는 작업을 수행한다면 네트워크 병목현상`이 발생해 노는 클러스터들이 생길 것이다.
